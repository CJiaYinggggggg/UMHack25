<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Models Overview</title>
  <link rel="stylesheet" href="style1.css" />
</head>
<body>
  <header>
    <h1>Models</h1>
    <nav>
      <a href="index1.html">&#8592; Home</a>
    </nav>
  </header>

  <div class="container">
    <div class="grid">
      
      <!-- HMM Card -->
      <div class="card">
        <h2>Hidden Markov Model (HMM)</h2>
        <p>An HMM uses latent (hidden) states to model market regimes. It consists of:</p>
        <ul>
          <li><strong>States:</strong> e.g., Bull, Bear.</li>
          <li><strong>Transition Matrix:</strong> Probabilities of switching between states.</li>
          <li><strong>Emission Probabilities:</strong> Likelihood of observations given a state.</li>
        </ul>

        <h3>Data Collection and Preparation</h3>
        <ul>
          <li><strong>On-chain cryptocurrency data:</strong> blockchain metrics like transactions, volume, etc.</li>
          <li><strong>Macroeconomic indicators:</strong> DFF, CPIAUCSL, GDPC1, UNRATE, DTWEXB, M2SL</li>
        </ul>

        <h3>Feature Engineering</h3>
        <ul>
          <li><strong>Returns and Log Returns</strong></li>
          <li><strong>Volatility</strong></li>
          <li><strong>Moving Averages (MA10)</strong></li>
          <li><strong>Rate of Change (ROC_5, ROC_10, ROC_20)</strong></li>
          <li><strong>Volume Change</strong></li>
          <li><strong>Fractional Price Relationships</strong>
            <ul>
              <li>Frac_Open_Close</li>
              <li>Frac_Open_High</li>
              <li>Frac_Open_Low</li>
              <li>Frac_High_Low</li>
            </ul>
          </li>
          <li><strong>ATR_14</strong></li>
          <li><strong>RSI_14</strong></li>
        </ul>

        <h3>Feature Selection</h3>
        <ul>
          <li>Frac_High_Low</li>
          <li>ATR_14</li>
          <li>Returns</li>
          <li>macro_index_kernel</li>
        </ul>

        <h3>Model Training</h3>
        <ul>
          <li>Data split: train/test/validate</li>
          <li>Grid Search for hyperparameters</li>
        </ul>

        <h3>Regime Identification</h3>
        <ul>
          <li>Different states like bull, bear, sideways</li>
          <li>Enables regime-specific strategies</li>
        </ul>

        <h3>Datetime Segmentation</h3>
        <ul>
          <li>Segment data by regime</li>
          <li>Train and backtest regime-specific models</li>
        </ul>
      </div>

      <!-- XGBoost Card -->
      <div class="card">
        <h2>XGBoost</h2>
        <p>XGBoost is a gradient boosting framework that uses decision trees.</p>
        <ul>
          <li><strong>Boosting:</strong> Sequential learning of weak models</li>
          <li><strong>Regularization:</strong> L1 and L2 support to prevent overfitting</li>
          <li><strong>Parallelization:</strong> Speed with large datasets</li>
        </ul>

        <h3>Step 1</h3>
        <p>Load regime-specific dataset: <code>regimes_0.csv</code>, <code>regimes_1.csv</code>, ...</p>

        <h3>Step 2</h3>
        <p>Drop unimportant columns (based on HMM selection)</p>

        <h3>Step 3 - Creating Rolling Windows</h3>
        <p>Transform time series into supervised format:</p>
        <pre><code>def create_window_sequences(self, df, top_features):
    ...
    return sequences, targets
</code></pre>

        <h3>Step 4 - Feature Scaling</h3>
        <pre><code>def prepare_data(self, df, top_features):
    ...
    return X_scaled, y
</code></pre>

        <h3>Step 5</h3>
        <p>Perform Train-Test Split</p>

        <h3>Step 6</h3>
        <p>Train XGBoost model on windows</p>

        <h3>Step 7 - Optimization</h3>
        <p>Time-aware cross-validation + hyperparameter tuning</p>
        <pre><code>def optimize_model(self, X_train, y_train):
    ...
    return self.models[model_type]
</code></pre>
      </div>

      <!-- LSTM Card -->
      <div class="card">
        <h2>Long Short-Term Memory (LSTM)</h2>
        <p>LSTM is ideal for modeling sequences like time series:</p>
        <ul>
          <li><strong>Memory Cells:</strong> Retain long-term patterns</li>
          <li><strong>Gates:</strong> Learn when to store, forget, or output info</li>
          <li><strong>Training:</strong> Backpropagation Through Time + gradient clipping</li>
        </ul>
        <p>Used to forecast cryptocurrency price movements.</p>
      </div>

    </div>
  </div>

  <footer>
    <p>&copy; 2025 QuantDoc</p>
  </footer>
</body>
</html>
