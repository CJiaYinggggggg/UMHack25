<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Models Documentation</title>
  <link rel="stylesheet" href="styles.css">
</head>
<body>
  <header>
    <h1>Models</h1>
    <p>An overview of the machine learning models used in our trading framework</p>
  </header>

  <nav>
    <ul>
      <li><a href="index.html">Home</a></li>
      <li><a href="installation.html">Installation</a></li>
      <li><a href="usage.html">Usage Guide</a></li>
      <li><a href="api.html">API Reference</a></li>
      <li><a href="examples.html">Program Flow</a></li>
      <li><a href="models.html" class="active">Models</a></li>
    </ul>
  </nav>

  <main>
    <!-- Hidden Markov Model Section -->
    <section class="container">
      <h2>Hidden Markov Model (HMM)</h2>
      <p>An HMM uses latent (hidden) states to model market regimes. It consists of:</p>
      <ul>
        <li><strong>States:</strong> e.g., Bull, Bear.</li>
        <li><strong>Transition Matrix:</strong> Probabilities of switching between states.</li>
        <li><strong>Emission Probabilities:</strong> Likelihood of observations given a state.</li>
      </ul>
      
      <h3>Data Collection and Preparation</h3>
      <ul>
        <li><strong>On-chain cryptocurrency data:</strong> blockchain metrics like transactions, volume, etc.</li>
        <li><strong>Macroeconomic indicators:</strong> DFF (Federal Funds Effective Rate), CPIAUCSL (CPI for All Urban Consumers), GDPC1 (Real GDP), UNRATE (Unemployment Rate), DTWEXB (U.S. Dollar Index), M2SL (Monetary Policy), S&P 500.</li>
        <li><strong>Source: </strong> Fred <a href="https://fred.stlouisfed.org">(https://fred.stlouisfed.org)</a> </li>
      </ul>
      
      <h3>Feature Engineering</h3>
      <ul>
        <li><strong>Returns & Log Returns:</strong> Measure price changes between periods.</li>
        <li><strong>Volatility:</strong> Price fluctuation/dispersion.</li>
        <li><strong>Moving Averages (MA10):</strong> 10-period SMAs.</li>
        <li><strong>ROC (5, 10, 20):</strong> Price momentum over respective windows.</li>
        <li><strong>Volume Change:</strong> Trading volume fluctuations.</li>
        <li><strong>Fractional Relationships:</strong> Frac_Open_Close, Frac_Open_High, Frac_Open_Low, Frac_High_Low.</li>
        <li><strong>ATR_14 & RSI_14:</strong> Volatility and momentum indicators.</li>
      </ul>
      
      <h3>Feature Selection</h3>
      <ul>
        <li>Frac_High_Low (volatility)</li>
        <li>ATR_14 (volatility)</li>
        <li>Returns (price changes)</li>
        <li>macro_index_kernel (macroeconomic composite)</li>
      </ul>
      
      <h3>Model Training</h3>
      <ul>
        <li>Train/test/validation split</li>
        <li>Grid Search for hyperparameter tuning</li>
      </ul>
      
      <h3>Regime Identification & Segmentation</h3>
      <ul>
        <li>Detect market states (bull, bear, sideways)</li>
        <li>Segment data by regime for analysis and backtesting</li>
      </ul>
    </section>

    <!-- XGBoost Section -->
    <section class="container">
      <h2>XGBoost</h2>
      <p>Gradient boosting framework using decision trees, with:</p>
      <ul>
        <li><strong>Boosting:</strong> Sequentially add weak learners.</li>
        <li><strong>Parallelization:</strong> Efficient on large datasets.</li>
      </ul>

      <h3>Workflow Steps</h3>
      <ol>
        <li>Load regime-specific CSVs (regimes_0.csv, regimes_1.csv, ...).</li>
        <li>Create rolling windows (<code>create_window_sequences</code>).</li>
        <pre><code>def create_window_sequences(self, df, top_features):
          data = df[top_features].values
          targets_data = df['price_change'].values
  
          total_samples = len(data) - self.window_size
          # total_samples = len(data) - 2 * self.window_size
          if total_samples <= 0:
              raise ValueError("Not enough data for the given window size.")
  
          # Use NumPy strides to efficiently build rolling windows
          shape = (total_samples, self.window_size, data.shape[1])
          strides = (data.strides[0], data.strides[0], data.strides[1])
          windows = np.lib.stride_tricks.as_strided(data, shape=shape, strides=strides)
  
          sequences = windows.reshape(total_samples, -1)
          # targets = targets_data[self.window_size * 2:]
          targets = targets_data[self.window_size:]
  
          return sequences, targets</code></pre>
        <li>Scale features (<code>prepare_data</code>).</li>
        <li>Train-test split.</li>
        <li>Model training.</li>
        <li>Time-series CV & RandomizedSearchCV (<code>optimize_model</code>).</li>
        <pre><code>def optimize_model(self, X_train, y_train, model_type='xgb', n_iter=20, cv=5):
          def time_series_split(X, n_splits):
              n_samples = len(X)
              k_fold_size = n_samples // n_splits
              indices = np.arange(n_samples)
              for i in range(n_splits):
                  test_start = k_fold_size * i
                  test_end = k_fold_size * (i + 1) if i < n_splits - 1 else n_samples
                  train_indices = indices[:test_start]
                  test_indices = indices[test_start:test_end]
                  yield train_indices, test_indices
  
          param_grid = self.param_distributions[model_type]
          base_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42, tree_method='hist')
          ts_cv = list(time_series_split(X_train, n_splits=cv))
  
          random_search = RandomizedSearchCV(
              estimator=base_model,
              param_distributions=param_grid,
              n_iter=n_iter,
              cv=ts_cv,
              scoring='neg_mean_squared_error',
              random_state=42,
              n_jobs=-1,
              verbose=2
          )
  
          random_search.fit(X_train, y_train)
          self.best_params = random_search.best_params_
          self.best_score = random_search.best_score_
          self.models[model_type] = random_search.best_estimator_
          print("\nBest parameters found:")
          print(self.best_params)
          print(f"Best score: {self.best_score:.4f}")
          return self.models[model_type]</code></pre>
      </ol>

    </section>

    <!-- LSTM Section -->
    <section class="container">
      <h2>Long Short-Term Memory (LSTM)</h2>
      <p>LSTM networks are widely chosen for Bitcoin price prediction due to their proven effectiveness in capturing complex patterns within volatile and nonlinear financial time series data.</p>
      <ul>
        <li><strong>It remembers long-term patterns,</strong> so it can learn from past price moves and use that memory to predict future Bitcoin prices.</li>
        <li><strong>It handles noisy, jumpy data well,</strong> meaning even when Bitcoinâ€™s price swings up and down sharply, the model still makes solid predictions.</li>
        <li><strong>It can use many inputs at once, </strong> like price history, trading volume, and economic indicators, for a fuller picture and better forecasts.</li>
      </ul>
      <p>Applied to predict future price movements from historical windows.</p>
    </section>
  </main>

  <footer>
    <p>&copy; 2025 QuantDoc. All rights reserved.</p>
  </footer>
</body>
</html>
